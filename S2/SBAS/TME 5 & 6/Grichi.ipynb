{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzMJ2QtGxpkq"
   },
   "source": [
    "<h1><b>Statistique en Bioinformatique : </b> TME 5 et 6 </h1>\n",
    "<br>\n",
    "L’objectif de ce TME est:\n",
    "<br>\n",
    "<ul>\n",
    "<li> implémenter l'algorithme de Viterbi et l'estimation des paramètres (en utilisant le Viterbi training)\n",
    "pour l'exemple du occasionally dishonest casino.   </li> \n",
    "</ul>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p><b>Soumission</b></p>\n",
    "<ul>\n",
    "<li>Renomer le fichier TME5_6.ipynb pour NomEtudiant1_NomEtudiant2.ipynb </li>\n",
    "<li>Soumettre via moodle </li>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiohDpWCxpkv"
   },
   "source": [
    "Nom etudiant 1 : Grichi Ihsân\n",
    "<br>\n",
    "Nom etudiant 2 :\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6n5Srpuxpkv"
   },
   "source": [
    "<h3>Introduction</h3>\n",
    "Un casino parfois malhonnête (occasionally dishonest casino) utilise 2 types de pieces : fair et unfair. <br>\n",
    "La matrice de transition entre les états cachés est:<br>\n",
    "${\\cal S}=\\{F,U\\}$ (fair, unfair):\n",
    "$$\n",
    "p = \\left(\n",
    "\\begin{array}{cc}\n",
    "0.99 & 0.01\\\\\n",
    "0.05 & 0.95\n",
    "\\end{array}\n",
    "\\right)\\ ,\n",
    "$$\n",
    "\n",
    "les probabilités d'émission des symboles \n",
    "${\\cal O} = \\{H,T\\}$ (head, tail):\n",
    "\\begin{eqnarray}\n",
    "e_F(H) =  0.5 &\\ \\ \\ \\ &\n",
    "e_F(T) = 0.5 \\nonumber\\\\\n",
    "e_U(H) = 0.9 &\\ \\ \\ \\ &\n",
    "e_U(T) = 0.1 \\nonumber\n",
    "\\end{eqnarray}\n",
    "\n",
    "<br> Et la condition initiale $\\pi^{(0)} = (0.999,0.001)$ (le jeux commence presque toujours avec le pieces juste (fair)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKz1fEeIxpkw"
   },
   "source": [
    "<b>Exercice 1</b>:\n",
    "<u>Simulation</u>: Écrire une fonction qui simule $T$ jets de pièces. \n",
    "La fonction renverra un tableau à deux colonnes correspondant \n",
    "aux valeurs simulées pour les états cachés $X_t$ \n",
    "(type de dés utilisée, “F” ou “U”) et aux symboles observées $Y_t$ \n",
    "(résultat du jet de dés, “H” ou “T”). On simulera une séquence\n",
    "de longueur 2000 qu'on gardera pour les applications ultérieures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "txZ2YCPbxpkx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#states\n",
    "S = { 0:'F',1 :'U'}\n",
    "\n",
    "#transition probability matrix\n",
    "Pij = np.array([[0.99,0.01], [0.05,0.95]])\n",
    "\n",
    "#emision symbols \n",
    "O = {0:'H', 1: 'T'}\n",
    "\n",
    "#emission probability matrix\n",
    "Ei = np.array([[0.5,0.5], [0.9,0.1]]) #ça aurait dû être Eio\n",
    "\n",
    "# initial Condition\n",
    "pi0=np.array([0.999,0.001])\n",
    "\n",
    "#number of jets\n",
    "T = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5OIqLuzAxpkz"
   },
   "outputs": [],
   "source": [
    "import random as rd\n",
    "\n",
    "# Fonction qui simule T jets de pieces\n",
    "def jets(T, pi0, Eij, Pij):\n",
    "    \"\"\"\n",
    "      simulation of occasionally dishonest casino\n",
    "      input1 T: number of jets\n",
    "      input2 pi0: initial condition\n",
    "      input3 Eij: emission probability matrix\n",
    "      input4 Pij: transition probability matrix\n",
    "      output1 jetsRes: matrix |2xT| containing simulations\n",
    "    \"\"\"\n",
    "    # Creation du tableau\n",
    "    jetsRes = np.zeros((T,len(pi0)),dtype=int)\n",
    "    \n",
    "    \n",
    "    PI0 = pi0.copy()\n",
    "    PI0 = np.cumsum(PI0)\n",
    "    \n",
    "    EIJ = Eij.copy()\n",
    "    EIJ = np.cumsum(EIJ, axis = 1)\n",
    "    \n",
    "    PIJ = Pij.copy()\n",
    "    PIJ = np.cumsum(PIJ, axis = 1) \n",
    "    \n",
    "    jet1 = rd.random()\n",
    "    etat = 0\n",
    "    \n",
    "    jet2 = rd.random()\n",
    "    obs = 0\n",
    "    \n",
    "    while jet1 >= PI0[etat]:\n",
    "        etat+=1\n",
    "    \n",
    "    while jet2 >= EIJ[etat, obs]:\n",
    "        obs+=1\n",
    "    \n",
    "    jetsRes[0] = [etat, obs]\n",
    "    \n",
    "    for t in range(1, T):\n",
    "        \n",
    "        jet1 = rd.random()\n",
    "        i = 0\n",
    "        \n",
    "        while jet1 >= PIJ[etat, i]:\n",
    "            i+=1\n",
    "        \n",
    "        etat = i\n",
    "        \n",
    "        jet2 = rd.random()\n",
    "        j = 0\n",
    "        \n",
    "        while jet2 >= EIJ[etat, j]:\n",
    "            j+=1\n",
    "            \n",
    "        obs = j\n",
    "        \n",
    "        jetsRes[t] = [etat, obs]\n",
    "    return jetsRes\n",
    "\n",
    "\n",
    "\n",
    "def printSimulation(resultat):\n",
    "    for i in resultat : \n",
    "        print (S[i[0]], O[i[1]])\n",
    "\n",
    "jetsRes = jets(T, pi0, Ei, Pij)\n",
    "#printSimulation(jetsRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpGzwVdIxpk0"
   },
   "source": [
    "<b>Exercice 2</b>: <u>Algorithme de Viterbi </u>: Écrire une fonction qui permet\n",
    "de déterminer la séquence $(i^\\star_t)_{t=0:T}$ d'états cachés\n",
    "plus probable, ainsi que sa probabilité. Pour tester votre fonction utiliser le résultat de la \n",
    "simulation (2éme colonne) de la question 1. Comparer $(i^\\star_t)_{t=0:T}$ avec\n",
    "les vrais états cachés (1ère colonne de la simulation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GCN_KQ-txpk1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0. -inf]\n",
      "erreur d'estimation de viterbi:\n",
      "15.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-46a19c374954>:21: RuntimeWarning: divide by zero encountered in log\n",
      "  logpi0 = np.log(pi0)\n"
     ]
    }
   ],
   "source": [
    "# Algorithme de Viterbi\n",
    "import operator\n",
    "\n",
    "def viterbi(jets, Pij, Ei, pi0, nS, nO, enLog):\n",
    "    \"\"\"\n",
    "    Implement Viterbi algorithm\n",
    "    input1 jets: matrix |2xT| containing simulations\n",
    "    input4 Pij: transition probability matrix\n",
    "    input3 Ei: emission probability matrix\n",
    "    input4 pi0: initial condition\n",
    "    input5 nS: number of states\n",
    "    input6 nO: number of observations\n",
    "    input7 enLog: bool, when True we apply log to avoid underflow\n",
    "    output1 i_star: most problable path\n",
    "    output2 prob: probability associated to the most problable path\n",
    "    \"\"\"\n",
    "    \n",
    "    obs = jets[:,1]\n",
    "    T = len(obs) #Nombre d'observations (longueur des observations)\n",
    "    logPij = np.log(Pij)\n",
    "    logpi0 = np.log(pi0)\n",
    "    logEi = np.log(Ei)\n",
    "    i_star = np.zeros((T))\n",
    "    prob = 1\n",
    "    \n",
    "    v = np.zeros((T, nS))\n",
    "    for i in range(nO):\n",
    "        if enLog :\n",
    "            v[0, i] = logpi0[i] + logEi[i, obs[0]]\n",
    "        else :\n",
    "            v[0, i] = pi0[i] * Ei[i, obs[0]]\n",
    "        \n",
    "    for i in range(1, T):\n",
    "        if enLog:\n",
    "            v[i, 0] = logEi[0, obs[i]] + max ( v[i-1, 0] + logPij[0, 0], v[i-1, 1] + logPij[1, 0] )\n",
    "        else :\n",
    "            v[i, 0] = Ei[0, obs[i]] * max ( v[i-1, 0] * Pij[0, 0], v[i-1, 1] * Pij[1, 0] )\n",
    "        if enLog:\n",
    "            v[i, 1] = logEi[1, obs[i]] + max( v[i-1, 1] + logPij[1, 1], v[i-1, 0] + logPij[0, 1] )\n",
    "        else:\n",
    "            v[i, 1] = Ei[1, obs[i]] * max( v[i-1, 1] * Pij[1, 1], v[i-1, 0] * Pij[0, 1] )\n",
    "    \n",
    "    \n",
    "    i_star[-1] = int(np.argmax(v[-1]))\n",
    "    for i in range(T-2, 0):\n",
    "        if enLog:\n",
    "            line = [v[i, 0] + logPij[0, int(i_star[i+1]) ], v[i, 1] + logPij[1, int(i_star[i+1]) ] ]\n",
    "        else:\n",
    "            line = [v[i, 0] * Pij[0, int(i_star[i+1]) ], v[i, 1] * Pij[1, int(i_star[i+1]) ] ]\n",
    "        \n",
    "        i_star[i] = np.argmax(line)\n",
    "        \n",
    "    return i_star, max([v[-1]])\n",
    "\n",
    "def analyseResultats(jets, estimation):    \n",
    "    \"\"\"\n",
    "    Compare expected and obtained paths\n",
    "    input1 jets: expected path\n",
    "    input2 estimation: obtained path\n",
    "    output1 error: percentage error\n",
    "    \"\"\"\n",
    "    error = np.mean(np.abs(jets[:, 0] - estimation)) * 100\n",
    "    return error\n",
    "\n",
    "i_est, P_est = viterbi(jetsRes, Pij, Ei, pi0, 2, 2, False)\n",
    "error = analyseResultats(jetsRes, i_est)\n",
    "print('erreur d\\'estimation de viterbi:')\n",
    "print(error,'%')\n",
    "#print('Probabilité estimé:')\n",
    "#print(P_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7NimDYwxpk2"
   },
   "source": [
    "<b>Exercice 3</b>: <u>Estimation des paramètres</u>\n",
    "<br>\n",
    "3.1) Écrire une fonction qu'utilise tous les résultats de la simulation\n",
    "(états et symboles) pour compter les nombres d'occurrence $N_{ij}$ est $M_{iO}$ définis en cours. Estimer $P_{ij}$ est $E_i(O)$. Attention, pour éviter les probabilités à zéro nous allons utiliser les pseudo-count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "msq33Rxjxpk2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pij estimé:\n",
      "[[0.98765432 0.01234568]\n",
      " [0.07284768 0.92715232]]\n",
      "\n",
      "Eio estimé:\n",
      "[[0.77200704 0.22799296]\n",
      " [0.9516129  0.0483871 ]]\n",
      "\n",
      "pi0 estimé:\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Estimation de Parametres par contage\n",
    "def nombresOccurrence(jets, nS, nO):\n",
    "    \"\"\"\n",
    "    Parameter estimation\n",
    "    input1 jets: matrix |2xT| containing data\n",
    "    input2 nS: number of states\n",
    "    input3 nO: number of observations\n",
    "    output1 Nij: transition probability matrix\n",
    "    output2 Mio: emission probability matrix\n",
    "    output3 pi0: initial condition \n",
    "    \"\"\"\n",
    "\n",
    "    Nij = np.ones((nS,nS)) #pseudo-count = 1\n",
    "    Mio = np.ones((nS,nO))  #pseudo-count = 1\n",
    "    pi0 = np.zeros((nS))\n",
    "    n = len(jets[:, 0])\n",
    "    \n",
    "    state = jets[0, 0]\n",
    "    obs = jets[0, 1]\n",
    "    Mio[state, obs] += 1\n",
    "    pi0[state] = 1\n",
    "    \n",
    "    \n",
    "    for i in range(1, n):\n",
    "        Nij[state, jets[i, 0]] += 1\n",
    "        Mio[state, jets[i, 1]] += 1\n",
    "        state = jets[i, 0]\n",
    "    \n",
    "    Nij /= np.sum(Nij, axis = 0)\n",
    "    Mio /= np.sum(Mio, axis = 0)\n",
    "    \n",
    "    return Nij.T, Mio.T, pi0\n",
    "\n",
    "Nij, Mio, pi0 = nombresOccurrence(jetsRes, 2, 2)\n",
    "\n",
    "print('Pij estimé:')\n",
    "print(Nij)\n",
    "print('\\nEio estimé:')\n",
    "print(Mio)\n",
    "print('\\npi0 estimé:')\n",
    "print(pi0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-ZYvpCgxpk3"
   },
   "source": [
    "3.2) <u> Viterbi training </u>: Écrire une fonction qui utilise\n",
    "seulement la séquence $(O_t)_{t=0:T}$ (2emme colonne de la simulation) pour estimer les\n",
    "paramètres $P_{ij}$ est $Ei(O)$. On s’arrêtera quand les différences entre les logVraissamblance est inférieur à 1e-04. Comparer les résultats de 3.1 et de 3.2 (3.2 avec plusieurs restarts,\n",
    "et avec initialisation des paramètres aléatoire).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dhKsGmO2xpk4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.48828671 -0.95108121]\n",
      "0.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b1b43a01dad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m#imprimer les Parametres du Viterbi Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mPij_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEi_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi0_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlLikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjetsRes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0mitCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlLikelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Le modèle est convergé après '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' itérations.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-b1b43a01dad4>\u001b[0m in \u001b[0;36mTraining\u001b[0;34m(jets, nS, nO)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnIteration\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mi_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPij_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEi_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi0_est\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mjets_est\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi_star\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mPij_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEi_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi0_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnombresOccurrence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjets_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-46a19c374954>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(jets, Pij, Ei, pi0, nS, nO, enLog)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogpi0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogEi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mEi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "\n",
    "# Initialisation aleatoire de Pij, Eij, pi0\n",
    "def InititRandom(nS, nO):\n",
    "    \"\"\"\n",
    "    randomly initialisations \n",
    "    input1 nS: number of states\n",
    "    input2 nO: number of observations\n",
    "    output1 Pij_init: transition probability matrix\n",
    "    output2 Ei_init: emission probability matrix\n",
    "    output3 pi0_init: initial condition \n",
    "    \"\"\"\n",
    "    \n",
    "    rd.seed(10)\n",
    "    \n",
    "    Pij_init = np.zeros((nS, nS))\n",
    "    \n",
    "    for i in range(nS):\n",
    "        for j in range(nS):\n",
    "            jet = rd.random()\n",
    "            Pij_init[i, j] = jet\n",
    "            \n",
    "    Pij_init /= np.sum(Pij_init, axis = 1).reshape(nS, 1)\n",
    "    \n",
    "    Ei_init = np.zeros((nO, nS))\n",
    "    \n",
    "    for i in range(nO):\n",
    "        for j in range(nS):\n",
    "            jet = rd.random()\n",
    "            Ei_init[i, j] = jet\n",
    "            \n",
    "    Ei_init /= np.sum(Ei_init, axis = 1).reshape(nS, 1)\n",
    "    \n",
    "    pi0_init = np.zeros((1, nS))\n",
    "    \n",
    "    for j in range(nS):\n",
    "        jet = rd.random()\n",
    "        pi0_init[0, j] = jet\n",
    "        \n",
    "    pi0_init /= np.sum(pi0_init)\n",
    "    \n",
    "    return Pij_init, Ei_init, pi0_init\n",
    "\n",
    "# Calcule log Vraissemblance\n",
    "def logLikelhihood(Aij,Bij,pi0,jets):\n",
    "    \"\"\"\n",
    "    compute Log Likelihood \n",
    "    input1 Pij: transition probability matrix\n",
    "    input2 Ei: emission probability matrix\n",
    "    input3 pi0: initial condition \n",
    "    input4 jets: matrix |2xT| containing data\n",
    "    \"\"\"\n",
    "    etat_seq = jets[:,0]\n",
    "    obs_seq = jets[:,1]\n",
    "    T = len(obs_seq) #Nombre d'observations (longueur des observations)\n",
    "    lLikelihood = np.log(pi0[etat_seq[0]]) + np.log(Bij[etat_seq[0], obs_seq[0]]) \n",
    "    for t in range(1, T):\n",
    "        lLikelihood += np.log(Aij[etat_seq[t-1], etat_seq[t]]) + np.log(Bij[etat_seq[t], obs_seq[t]])\n",
    "    return lLikelihood\n",
    "\n",
    "\n",
    "def Training(jets, nS, nO):\n",
    "    \"\"\"\n",
    "    Viterbi Training\n",
    "    input1 jets: matrix |2xT| containing data\n",
    "    input2 nS: number of states\n",
    "    input3 nO: number of observations\n",
    "    output1 Pij_est: transition probability matrix\n",
    "    output2 Ei_est: emission probability matrix\n",
    "    output3 pi0_est: initial condition \n",
    "    output4 lLikelihood: log Likelihood\n",
    "    \"\"\"\n",
    "    jets_est = np.array(jets)\n",
    "    Pij_est, Ei_est, pi0_est = InititRandom(nS, nO)\n",
    "    \n",
    "    nIteration = 10000\n",
    "    criterion = 1e-04\n",
    "    lLikelihood = np.zeros((nIteration))\n",
    "    t = 1\n",
    "    stop = False\n",
    "    while t < nIteration and stop == False:\n",
    "        i_star, prob = viterbi(jets, Pij_est, Ei_est, pi0_est[0], nS, nO, False)\n",
    "        jets_est[:, 0] = i_star\n",
    "        Pij_est, Ei_est, pi0_est = nombresOccurrence(jets_est, nS, nO)\n",
    "        lLikelihood[t] = logLikelhihood(Pij_est, Ei_est, pi0_est, jets_est)\n",
    "        if np.abs(lLikelihood[t-1] - lLikelihood[t]) < criterion:\n",
    "            stop = True\n",
    "        t+1  \n",
    "        \n",
    "    return Pij_est, Ei_est, pi0_est, lLikelihood\n",
    "    \n",
    "#imprimer les Parametres du Viterbi Training\n",
    "Pij_est, Ei_est, pi0_est, lLikelihood = Training(jetsRes, 2, 2)\n",
    "itCount = len(lLikelihood)\n",
    "print('Le modèle est convergé après '+str(itCount)+' itérations.')\n",
    "print('\\nPij estimée:')\n",
    "print(Pij_est)\n",
    "print('\\nEij estimée:')\n",
    "print(Ei_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6B-AX8Zxpk4"
   },
   "source": [
    "<font color=\"blue\">\n",
    "Remark:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7iq2fv5xpk5"
   },
   "source": [
    "3.3) <u>Viterbi training deuxième version</u>. \n",
    "<BR>Écrivez une version de 3.2 qui:\n",
    "- part plusieurs fois (100x) d'une initialisation aléatoire desparamètres de l'HMM,\n",
    "- utilise Viterbi training pour estimer les paramètres,\n",
    "- calcul la log-vraisemblance pour les paramètres estimés,\n",
    "- sauvegarde seulement l'estimation avec la valeur maximale de lalog-vraisemblance.\n",
    "\n",
    "Qu'est-ce que vous observez?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rwS987bpxpk5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur Pij estimée:\n",
      "[]\n",
      "\n",
      "Meilleur Eij estimée:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Viterbi Training  deuxiemme version\n",
    "\n",
    "def TrainingV2(jets, nS, nO, nIterat=100):\n",
    "    \"\"\"\n",
    "    Viterbi Training version 2.0\n",
    "    input1 jets: matrix |2xT| containing data\n",
    "    input2 nS: number of states\n",
    "    input3 nO: number of observations\n",
    "    input4 nIterat: number of iterations\n",
    "    output1 Pij_best: best transition probability matrix\n",
    "    output2 Ei_best: best emission probability matrix\n",
    "    output3 pi0_best: best initial condition \n",
    "    output4 lLikelihood_best: best log Likelihood\n",
    "    \"\"\"\n",
    "\n",
    "    Pij_best = []\n",
    "    Ei_best = []\n",
    "    pi0_best = []\n",
    "    lLikelihood_best = -10000\n",
    "    \n",
    "\n",
    "    return Pij_best, Ei_best, pi0_best, lLikelihood_best\n",
    "    \n",
    "\n",
    "# Imprimer les Parametres du Viterbi Training deuxiemme version\n",
    "nIterat = 100\n",
    "Pij_best, Ei_best, pi0_best, lLikelihood_best = TrainingV2(jetsRes, 2, 2, nIterat)\n",
    "\n",
    "print('Meilleur Pij estimée:');\n",
    "print(Pij_best)\n",
    "print('\\nMeilleur Eij estimée:')\n",
    "print(Ei_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4EHk9MKxpk6"
   },
   "source": [
    "<font color=\"blue\">\n",
    "Remark:\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TME5_6_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
