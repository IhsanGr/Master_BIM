{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMKZ5QVoBmjJ"
   },
   "source": [
    "<h1><b>Statistique en Bioinformatique : </b> TME9 </h1><br>\n",
    "\n",
    "L’objectif de ce TME est l'implementation de la méthode Expectation-Maximisation pour la recherche de motifs.\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p><b>Soumission</b></p>\n",
    "<ul>\n",
    "<li>Renomer le fichier TME9.ipynb pour NomEtudiant1_NomEtudiant2.ipynb </li>\n",
    "<li>Soumettre via moodle </li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_qH1CG7BmjM"
   },
   "source": [
    "<H1>Expectation-Maximisation Motif</H1>\n",
    "<br>\n",
    "La méthode EM (Expectation-Maximisation) permet de détecter des motifs dans un ensemble de séquences ADN ou protéiques reliées, non alignées. En particulier, étant donné un groupe de séquences de longueur $L$, dont on sait qu'elles partagent un motif commun de longueur $w$, l’algorithme EM:\n",
    "- infère un modèle $(\\Theta,Z)$ pour le motif;\n",
    "- localise l’occurrence du motif dans chaque séquence.\n",
    "\n",
    "$\\Theta$ representé la matrice des poids-positions $p_{c,k}$ du motif (où $c \\in \\{A,C,G,T\\}$ ou $c \\in \\{A,C,D,...,W\\}$  et $k \\in \\{0 \\dots w\\}$), $p_{c,0}$  est le vecteur de probabilités du modèle nul ou \"background\".\n",
    "$Ζ$ est la matrice des variables cachées, qui donnent les positions initiales du motif: \n",
    "- $Z_{i,j} = 1$, si le motif commence en position $j$ de la séquence $i$,\n",
    "- $Z_{i,j} = 0$, sinon. \n",
    "\n",
    "L’algorithme affine les paramètres du modèle de manière itérative par espérance-maximisation. Chaque itération $t$ se compose de deux étapes:\n",
    "- (E) Calcul des valeurs attendues $Ζ^{(t)}$ de $Ζ$, étant donnés $\\Theta^{(t-1)}$\n",
    "- (M) Estimation de  $\\Theta^{(t)}$  à partir de  $Ζ^{(t)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSue1iYeBmjO"
   },
   "source": [
    "1\\. Implémentez une fonction `read_training_file` pour lire le fichier d'entré qui contient un ensemble de séquences ADN non alignées. Pour simplifier nous allons utiliser les données vu en cours du fichier `toyEx.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aWQrgN0iBmjP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GTCAGG', 'GAGAGT', 'ACGGAG', 'CCAGTC']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nts = ['A', 'C', 'G', 'T']\n",
    "\n",
    "w = 3\n",
    "input_f = \"toyEx.txt\"\n",
    "\n",
    "def read_training_file(input_f):\n",
    "    \"\"\"\n",
    "    Read a file with no-aligned sequences\n",
    "    input input_f : file name\n",
    "    output seqs : list of sequences\n",
    "    \"\"\"\n",
    "    seqs = []\n",
    "    flux = open(input_f)\n",
    "    for line in flux:\n",
    "        line = line.rstrip()\n",
    "        seqs.append(line)\n",
    "    return seqs\n",
    "\n",
    "seqs = read_training_file(input_f)\n",
    "print (seqs) #['GTCAGG', 'GAGAGT', 'ACGGAG', 'CCAGTC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIHpbbKwBmjQ"
   },
   "source": [
    "2\\. Implémentez une fonction `initialiseP` pour initialiser la matrice poids-position $p_{c,k}$. On considère le modèle nul par défaut $p_0 = (0.25, 0.25, 0.25, 0.25)$. Pour initialiser $p^{(t)}$, on prend généralement un motif au hasard dans une sequence, et on fixe à $0.5$ les poids du nucleotide correspondant et à $\\frac{1-0.5}{3}$ les trois autres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "_zIZdJouBmjR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n",
      "[[0.25 0.   0.   0.  ]\n",
      " [0.25 0.   0.   0.  ]\n",
      " [0.25 0.   0.   0.  ]\n",
      " [0.25 0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "def initialiseP(seqs, w, alph):\n",
    "    \"\"\"\n",
    "    Initialise pc,k\n",
    "    input seqs : list of sequences\n",
    "    input w : motif length\n",
    "    input alph : alphabet (nucleotides or amino acids)\n",
    "    output P: position probability matrix\n",
    "    \"\"\"\n",
    "    q = len(alph)\n",
    "    D = {}\n",
    "    \n",
    "    for k in range(q):\n",
    "        D[k] = alph[k]\n",
    "    \n",
    "    P = np.zeros((q, w+1))\n",
    "    \n",
    "    seq = seqs[np.random.randint(len(seqs))]\n",
    "    start = np.random.randint(len(seq)-w)\n",
    "    motif = seq[start:start+w]\n",
    "    \n",
    "    P[:, 0] = 1/q\n",
    "    \n",
    "    return P\n",
    "\n",
    "#test\n",
    "p = initialiseP(seqs, w, nts)\n",
    "print (p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMqgrzYRBmjS"
   },
   "source": [
    "3\\. Implémenter une fonction `initialiseZ` pour initialiser la matrice $Z$ à uns. Rappelez-vous que la dimension de $Z$ est $nbSeq \\times (lenSeq -w +1)$, où $nbSeq$ est le nombre de sequences et $lenSeq$ est la taille/longueur des sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mghUiiW4BmjT"
   },
   "outputs": [],
   "source": [
    "def initialiseZ(seqs, w):\n",
    "    \"\"\"\n",
    "    Initialise Z\n",
    "    input seqs : list of sequences\n",
    "    input w : motif length\n",
    "    output Z :  matrix of motif start positions\n",
    "    \"\"\"\n",
    "    Z = []\n",
    "   \n",
    "    return Z\n",
    "\n",
    "Z = initialiseZ(seqs, w)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbSoL4ywBmjU"
   },
   "source": [
    "4\\. Écrivez une fonction `E_step` pour le pas Expectation qui estime $Z$ à partir de  $p_{c,k}$. \n",
    "Écrivez aussi une fonction `normaliseZ` pour normaliser $Z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oa3r0j3BmjV"
   },
   "outputs": [],
   "source": [
    "def E_step(seqs, P, Z, w, alph):\n",
    "    \"\"\"\n",
    "    Implement Expectation step\n",
    "    input seqs : list of sequences\n",
    "    input P : position probability matrix\n",
    "    input Z :  matrix of motif start positions\n",
    "    input w : motif length\n",
    "    input alph : alphabet (nucleotides or amino acids)\n",
    "    output Z :  matrix of motif start positions\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = initialiseZ(seqs, w)\n",
    "    \n",
    "    return Z\n",
    "\n",
    "def normaliseZ(z):\n",
    "    \"\"\"\n",
    "    Normalise Z matrix\n",
    "    input Z : unnormalised matrix\n",
    "    output Zn : normalised matrix\n",
    "    \"\"\"\n",
    "    return np.array([row/sum(row) for row in z])\n",
    "\n",
    "Z = E_step(seqs, p, Z, w, nts)\n",
    "z_norm = normaliseZ(Z)\n",
    "print(z_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odh27oHwBmjV"
   },
   "source": [
    "5\\. Implémentez une fonction `M_step` pour le pas Maximisation qui estime $p_{c,k}$ à partir de $Z$. \n",
    "Utilisez les \"pseudocounts\" pour éviter les probabilités ègales à zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VleAgdFtBmjW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def totalNumberofCH(seqs,alph):\n",
    "\n",
    "    q = len(alph)\n",
    "    totalN = np.zeros((q))\n",
    "    for i in range(q):\n",
    "        e = alph[i]\n",
    "        for seq in seqs:\n",
    "            for s in seq:\n",
    "                if(s == e):\n",
    "                    totalN[i]+=1\n",
    "    return totalN\n",
    "                    \n",
    "def M_step(seqs, Z, w, alph):\n",
    "    \"\"\"\n",
    "    Implement Expectation step\n",
    "    input seqs : list of sequences\n",
    "    input Z :  matrix of motif start positions\n",
    "    input w : motif length\n",
    "    input alph : alphabet (nucleotides or amino acids)\n",
    "    output P : position probability matrix\n",
    "    \"\"\"\n",
    "\n",
    "    P = []\n",
    "\n",
    "    \n",
    "    return P\n",
    "\n",
    "P = M_step(seqs, z_norm, w, nts)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37ciA9qLBmjY"
   },
   "source": [
    "6\\. Écrivez une fonction `likelihood` qui calcule la log-vraisemblance de l'ensemble des sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUMUQUwZBmjY",
    "outputId": "b679b7aa-6b80-496d-d6be-c6342913321d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "def likelihood(seqs, Z, P, w, alph):\n",
    "    \"\"\"\n",
    "    Implement log likelihood function of P\n",
    "    input seqs : list of sequences\n",
    "    input Z :  matrix of motif start positions\n",
    "    input p : position probability matrix\n",
    "    input w : motif length\n",
    "    input alph : alphabet (nucleotides or amino acids)\n",
    "    output lLikelihood : log likelihood of P \n",
    "\n",
    "    \"\"\"\n",
    "    M = len(seqs)\n",
    "    L = len(seqs[0])\n",
    "    lLikelihood = np.log((L-w+1)**-M)\n",
    "    \n",
    "      \n",
    "    return lLikelihood\n",
    "\n",
    "logvraisemblance = likelihood(seqs, Z, P, w, nts)\n",
    "print(logvraisemblance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFOgaK9eBmjZ"
   },
   "source": [
    "7\\. Implémentez l'algorithme Expectation-Maximisation. Vous calculerez la valeur de la log-vraisemblance totale du modèle à chaque iteration et l'algorithme prendra fin lorsque $\\Delta \\log \\text{Pr}(D | \\Theta) < \\varepsilon$. Utilisez $\\varepsilon = 1e-4$. Votre implementation devra renvoyer les paramètres du modele ($p$ et la log-likelihood associé), ainsi bien que la liste des meilleures positions du motif dans chaque sequence (matrice $Z$). Faites attention à utiliser $Z$ non-normalisé afin de trouver la log-vraisemblance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZXGq1_3Bmja"
   },
   "outputs": [],
   "source": [
    "def ExpectationMaximisation(seqs, w, alph, eps):\n",
    "    \"\"\"\n",
    "    Implement Expectation Maximisation algorithm\n",
    "    input seqs : list of sequences\n",
    "    input w : motif length\n",
    "    input alph : alphabet (nucleotides or amino acids)\n",
    "    input eps : threahold \n",
    "    output P : position probability matrix\n",
    "    output Z :  matrix of motif start positions\n",
    "    output lLikelihood : log likelihood of P \n",
    "    output pos_motif : positions of motifs in seqs\n",
    "    \"\"\"\n",
    "    P = initialiseP(seqs, w, alph)\n",
    "    Z = initialiseZ(seqs, w)\n",
    "    lLikelihood = []\n",
    "    pos_motif = []\n",
    "    \n",
    "\n",
    "    return (P, lLikelihood, Z, pos_motif)\n",
    "\n",
    "def analyse_results(results, seqs):\n",
    "    print('Les paramètres du modele:')\n",
    "    print('p:\\n',results[0])\n",
    "    print('\\n')\n",
    "    print('log-vraisemblance associé:',results[1][-1])\n",
    "    print('\\n')\n",
    "    print('Z:\\n',results[2])\n",
    "    print('\\nLes motifs:')\n",
    "    for i in range(len(seqs)):\n",
    "        print('seq'+str(i+1)+': '+ str(results[3][i]+1) + '  ' + seqs[i][results[3][i]:results[3][i]+w])\n",
    "\n",
    "    plt.plot(results[1])\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Log-vraisemblance')\n",
    "    plt.show()\n",
    "\n",
    "eps = 10**-4\n",
    "EMResults = ExpectationMaximisation(seqs, w, nts, eps)\n",
    "analyse_results(EMResults,seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZsOsS8yBmjb"
   },
   "source": [
    "8\\. Qu'est-ce que vous observez en exécutant l'algorithme EM plusieurs fois? Justifiez votre réponse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgXXj3dcBmjb"
   },
   "source": [
    "Reponse:\n",
    "\n",
    "<font color=\"blue\">\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WThFDcG5Bmjb"
   },
   "source": [
    "9\\. Pour éviter le problème identifié au point précedent, écrivez une fonction `EM_iteratif` qui exécute l'algorithme `EM` $N$ fois ($N=10$) et qui prend les paramètres associés à la meilleure log-vraisemblance. Trouvez-vous les bons motifs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiMm-jSkBmjc"
   },
   "outputs": [],
   "source": [
    "def EM_iteratif(N, seqs, w, alph, eps):\n",
    "    \"\"\"\n",
    "    Implement a iterative version of Expectation Maximisation algorithm\n",
    "    input N : number of iterations\n",
    "    input seqs : list of sequences\n",
    "    input w : motif length\n",
    "    input eps : threahold \n",
    "    output bestModel : the parameter of the best model\n",
    "    \"\"\"\n",
    "  \n",
    "    bestModel = P, Z, lLikelihood, pos_motif\n",
    " \n",
    "    return bestModel\n",
    "\n",
    "\n",
    "eps = 10**-4\n",
    "N=10\n",
    "meilleurEM = EM_iteratif(N, seqs, w, nts, eps)\n",
    "analyse_results(meilleurEM,seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "us2JZ9SRBmjc"
   },
   "source": [
    "10\\. Appliquez votre algorithme `EM` à l'ensemble des séquence du fichier `trainingSequences.txt` en utilisant $w=10$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yc5bUMIBmjd"
   },
   "outputs": [],
   "source": [
    "w= 10\n",
    "input_f = \"trainingSequences.txt\"\n",
    "seqs_train = read_training_file(input_f)\n",
    "print (seqs_train)\n",
    "eps = 10**-4\n",
    "N=10\n",
    "meilleurEM = EM_iteratif(N, seqs_train, w, nts, eps)\n",
    "analyse_results(meilleurEM,seqs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3ddFiW2Bmjd"
   },
   "source": [
    "11\\. Construire un LOGO pour le motif prédit avec le service <i>WebLogo</i>. Pour cela, identifiez le motif dans chaque séquence, utiliser <i>ClustalOmega</i> pour les aligner et puis <i>WebLogo</i> pour générer le LOGO. Ajouter le LOGO à votre réponse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sR5YLgIZBmjd"
   },
   "outputs": [],
   "source": [
    "fhandler = open('motifs.txt','w')\n",
    "for i in range(len(seqs_train)):\n",
    "    fhandler.write('>motif'+str(i+1)+'\\n')\n",
    "    fhandler.write(seqs_train[i][meilleurEM[3][i]:meilleurEM[3][i]+w])\n",
    "    fhandler.write('\\n')\n",
    "fhandler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lu09z4zBmje"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfmV6fjVBmje"
   },
   "source": [
    "12\\. Comparez les motifs trouvés par votre programme avec les motifs du fichier `testingSequences.txt`, où les vrais motifs sont montrés en lettre majuscule. Quelle est la performance de votre programme? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jh36eh-vBmje"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "motifs_extracted = []\n",
    "motifs_real = []\n",
    "\n",
    "\n",
    "input_f = \"testingSequences.txt\"\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TME9_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
