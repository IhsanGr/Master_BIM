{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ei9rT_XZ3SO5"
   },
   "source": [
    "### TME sur Echantillonage\n",
    "\n",
    "## Diffusion dans les graphes \n",
    "\n",
    "Au cours des vingt dernières années, les réseaux sociaux sont devenus un média d’information incontournable, mettant en jeu des dynamiques complexes de communication entre utilisateurs. La modélisation de la diffusion d’information sur les réseaux constitue depuis lors un enjeu majeur, pour diverses tâches\n",
    "telles que l’identification de leaders d’opinions, la prédiction ou la maximisation de l’impact d’un contenu diffusé, la détection de communautés d’opinions, ou plus généralement l’analyse des dynamiques du réseau considéré.\n",
    "\n",
    "Le modèle proposé par (Saito et al, 2009) considère une diffusion en cascade dans laquelle l'information transite de noeuds en noeuds du réseau en suivant des relations d'influence entre les utilisateurs. Lorsqu'un utilisateur est ``infecté'' par une information, il possède une chance unique de la retransmettre à chacun de ses successeurs dans le graphe, selon une probabilité définie sur le lien correspondant. Le modèle définit en fait deux paramètres sur chaque lien $(u,v)$ du graphe:\n",
    "\n",
    "\n",
    "*   $k_{u,v}$: la probabilité que l'utilisateur $u$ transmette une information diffusée à $v$\n",
    "*   $r_{u,v}$: si la transmission s'effectue, l'utilisateur $v$ la reçoit au temps $t_v=t_u+\\delta$, avec $\\delta \\sim Exp(r_{u,v})$\n",
    "\n",
    "Pour utiliser ce modèle, on devra donc échantillonner selon la distribution exponentielle. Pour commencer, on cherche alors à écrire une méthode $exp(rate)$ qui échantillonne des variables d'une loi exponentielle selon le tableau d'intensités $rate$ passé en paramètre. Cet échantillonnage se fera par **Inverse Transform Sampling**. Pour éviter les divisions par 0, on ajoutera $1e-200$ aux intensités qui valent 0.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f1aE9ijomC1j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98796784 0.49198855 0.33501196]\n",
      " [0.25022762 0.19644862 0.16723749]]\n",
      "[[1.00356177 0.50416273 0.34028414]\n",
      " [0.25231623 0.20024732 0.16911951]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "def exp(rate): # note: rate correspond à lambda dans les formules usuelles de la loi exponentielle\n",
    "    #>>>>>>>>>>\n",
    "    # votre code ici\n",
    "    # 1. Avoir calculé x = F(u, rate) comme en TD\n",
    "    # 2. Retourner un tirage aléatoire à partir de np.random.rand\n",
    "    # note: si on donne plusieurs valeur de rate, on fera autant de tirages (comme ci-dessous)\n",
    "    #<<<<<<<<<<\n",
    "    rate = np.where(rate==0,1e-200,rate)\n",
    "    x = np.random.rand(*rate.shape)\n",
    "    return -np.log(1.0-x)/rate\n",
    "\n",
    "#Test : on sait que l'espérance de la loi exp est 1/lambda \n",
    "a=exp(np.array([[1,2,3],[4,5,6]]))\n",
    "for i in range(10000):\n",
    "    a+=exp(np.array([[1,2,3],[4,5,6]]))\n",
    "print(a/10000) # calcul de l'espérance\n",
    "\n",
    "# Pour comparaison avec la méthode de référence de numpy:\n",
    "# ATTENTION, la méthode attend un paramètre 1/lambda (et non lambda)\n",
    "a=np.random.exponential(1.0/np.array([[1,2,3],[4,5,6]]))\n",
    "for i in range(10000):\n",
    "    a+=np.random.exponential(1.0/np.array([[1,2,3],[4,5,6]]))\n",
    "print(a/10000) # calcul de l'espérance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2FBZBggg1B7"
   },
   "source": [
    "Vérification :\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "[[0.98796784 0.49198855 0.33501196]\n",
    " [0.25022762 0.19644862 0.16723749]]\n",
    "[[1.00356177 0.50416273 0.34028414]\n",
    " [0.25231623 0.20024732 0.16911951]]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHJPFXBKoqIf"
   },
   "source": [
    "Soit le graphe de diffusion donné ci dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eBihGMdL7tZw"
   },
   "outputs": [],
   "source": [
    "\n",
    "names={0:\"Paul\",1:\"Jean\",2:\"Hector\",3:\"Rose\",4:\"Yasmine\",5:\"Léo\",6:\"Amine\",7:\"Mia\",8:\"Quentin\",9:\"Gaston\",10:\"Louise\"}\n",
    "k={(0,1):0.9,(1,0):0.9,(1,2):0.2,(2,3):0.5,(3,2):0.4,(2,4):0.9,(4,3):0.9,(1,3):0.5,(2,5):0.5,(5,7):0.7,(1,6):0.2,(6,7):0.1,(1,8):0.8,(8,9):0.2,(1,10):0.5,(10,9):0.9,(8,1):0.8}\n",
    "r={(0,1):0.2,(1,0):3,(1,2):1,(2,3):0.2,(3,2):0.5,(2,4):10,(4,3):2,(1,3):2,(2,5):0.5,(5,7):15,(1,6):3,(6,7):4,(1,8):0.8,(8,9):0.1,(1,10):12,(10,9):1,(8,1):14}\n",
    "graph=(names,k,r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx2XlKT97sbh"
   },
   "source": [
    "La fonction display_graph ci dessous permet de visualiser le graphe de diffusion correspondant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "M-etZqDj3PXW",
    "outputId": "c1ce6ed9-a5cd-4148-f6d6-885cf77a9ff9"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] \"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m             stdout_data, stderr_data, process = call_graphviz(\n\u001b[0m\u001b[1;32m   1924\u001b[0m                 \u001b[0mprogram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     process = subprocess.Popen(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mprogram_with_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1701\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2af7d4217ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0moutfile\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdisplay_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-2af7d4217ed0>\u001b[0m in \u001b[0;36mdisplay_graph\u001b[0;34m(graph_data, style, graph_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# sauvegarde et affichage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0moutfile\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0moutfile\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pydot.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(path, f, prog, encoding)\u001b[0m\n\u001b[1;32m   1741\u001b[0m                     encoding=None):\n\u001b[1;32m   1742\u001b[0m                 \u001b[0;34m\"\"\"Refer to docstring of method `write.`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m                 self.write(\n\u001b[0m\u001b[1;32m   1744\u001b[0m                     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m                     encoding=encoding)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pydot.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, path, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1826\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1931\u001b[0m                 args[1] = '\"{prog}\" not found in path.'.format(\n\u001b[1;32m   1932\u001b[0m                     prog=prog)\n\u001b[0;32m-> 1933\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1934\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path."
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "style = { \"bgcolor\" : \"#6b85d1\", \"fgcolor\" : \"#FFFFFF\" }\n",
    "\n",
    "def display_graph ( graph_data, style, graph_name=\"diffusion_graph\" ):\n",
    "    graph = pydot.Dot( graph_name , graph_type='digraph')\n",
    "    names,k,r=graph_data\n",
    "    # création des noeuds du réseau\n",
    "    for (i,name) in names.items():\n",
    "        new_node = pydot.Node( str(i)+\"_\"+name,\n",
    "                               style=\"filled\",\n",
    "                               fillcolor=style[\"bgcolor\"],\n",
    "                               fontcolor=style[\"fgcolor\"] )\n",
    "        graph.add_node( new_node )\n",
    "\n",
    "    # création des arcs\n",
    "    for edge,valk in k.items():\n",
    "        valr=r[edge]\n",
    "        n1=str(edge[0])+\"_\"+names[edge[0]]\n",
    "        n2=str(edge[1])+\"_\"+names[edge[1]]\n",
    "        new_edge = pydot.Edge ( n1, n2, label=\"k=\"+str(valk)+\",r=\"+str(valr))\n",
    "        graph.add_edge ( new_edge )\n",
    "\n",
    "    # sauvegarde et affichage\n",
    "    outfile = graph_name + '.png'\n",
    "    graph.write_png( outfile )\n",
    "    img = mpimg.imread ( outfile )\n",
    "    plt.imshow( img )\n",
    "display_graph(graph,style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0_Ol6AgQa9g"
   },
   "source": [
    "On souhaite être capable d'estimer les probabilités marginales d'infection des différents utilisateurs du réseau par une information pour laquelle on connaît les sources (i.e., les utilisateurs infectés au temps 0). \n",
    "\n",
    "Etant donnés les cycles possibles dans le graphe de diffusion, considérer un calcul exact des probabilités d'infection des différents utilisateurs sachant le début de la diffusion est inenvisageable : il faudrait considérer toutes les combinaisons possibles (infinies) de temps d'infection pour tous les utilisateurs non sources. \n",
    "\n",
    "Une possibilité pour calculer ces probabilités d'infections est de travailler par échantillonnage de Monte Carlo: on réalise $n$ tirages d'infections connaissant les sources et on recense le ratio des simulations dans lesquelles chacun des utilisateurs est infecté avant un temps $maxT$.  \n",
    "\n",
    "L'idée est alors dans un premier temps d'écrire une méthode $simulation(graph,sources)$ qui, à partir d'une liste de sources, retourne les temps d'infection de l'ensemble des noeuds en fin de diffusion, sous la forme d'un tableau où chaque case $i$ contient le temps d'infection du noeud $i$. Si le noeud $i$ n'a pas été infecté ou bien si il l'a été après un temps maximal $maxT$, la case $i$ contient alors la valeur $maxT$. \n",
    "\n",
    "Le pseudo-code de la méthode de simulation est donné ci dessous, avec $t_i$ le temps d'infection courant du noeud $i$:\n",
    "```\n",
    "ti=maxT pour tout i non source \n",
    "Tant qu'il reste des infectieux dont le temps est < maxT:\n",
    "  i=Infectieux de temps d'infection minimal\n",
    "  Pour tout noeud j tel que tj>ti:\n",
    "    sampler x selon Bernoulli(kij)\n",
    "    si x==1:\n",
    "       sampler delta selon Exp(rij)\n",
    "       t=ti+delta  \n",
    "       si t<tj: tj=t \n",
    "  Retrait de i de la liste des infectieux\n",
    "```\n",
    "Complétez le code de la fonction donnée ci-dessous: \n",
    "\n",
    "**Note:** les résultats de référence ne seront obtenus que si on fait les appels à random dans le même ordre que dans dans la correction de référence... Ce sera le cas si vous suivez les consignes détaillées ci-dessous. Mais vous pouvez aussi tenter de travailler directement à partir de l'algorithme ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FgfnYxbNTGDa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          6.37062627 10.         10.         10.         10.\n",
      " 10.         10.          6.55971741  8.45768892  6.6581452 ]\n",
      "[ 0.          2.97007182 10.          3.04941061 10.         10.\n",
      " 10.         10.          3.63849864  4.03296435  3.06090791]\n",
      "[ 0. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "[0.00000000e+00 0.00000000e+00 1.00000000e+01 1.00000000e+01\n",
      " 1.00000000e+01 1.00000000e+01 9.25654159e-03 1.00000000e+01\n",
      " 1.02250914e+00 1.00000000e+01 1.00000000e+01]\n",
      "[ 0.          0.         10.         10.         10.         10.\n",
      " 10.         10.          1.41975241 10.         10.        ]\n",
      "[ 0.          0.         10.         10.         10.         10.\n",
      " 10.         10.          1.73693508 10.          0.08144123]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "maxT=10\n",
    "\n",
    "# returns dense numpy arrays of k,r parameters for graph links fr -> to \n",
    "def get_kr_for(graph,fr,to):\n",
    "    _,gk,gr=graph\n",
    "    k = np.array([[gk.get((i, v),0) for v in to] for i in fr])\n",
    "    r = np.array([[gr.get((i, v),0) for v in to] for i in fr])\n",
    "    return k,r\n",
    "\n",
    "def simulation(graph,sources, maxT):\n",
    "    nbNodes=len(names)\n",
    "    infectious = np.ones(len(graph[0]))*maxT\n",
    "    for source in sources:\n",
    "        infectious[source] = 0\n",
    "    times = np.copy(infectious)\n",
    "    \n",
    "    # On boucle tant qu'il reste des contaminants (ie: qu'il reste des 0 dans infectious)\n",
    "    while 0 in infectious:\n",
    "        # trouver le noeud contaminant à cette itération = argmin dans infectious\n",
    "        Noeud_contaminant = np.argmin(infectious)\n",
    "        \n",
    "        # trouver le temps associé à la contamination: Tref\n",
    "        Tref = times[Noeud_contaminant]\n",
    "        \n",
    "        # éliminer le noeud en mettant sa valeur à maxT dans infectious => il ne sera plus sélectionné\n",
    "        infectious[Noeud_contaminant] = maxT\n",
    "        \n",
    "        # trouver les indices des cibles (temps de contamination > Tref)\n",
    "        targets = np.where(times > Tref)[0]\n",
    "\n",
    "        # trouver les paramètres des modèles entre le noeud source et les cibles:     \n",
    "        params = get_kr_for(graph,[Noeud_contaminant], targets) # récupération des paramètres vers les cibles\n",
    "\n",
    "        for j in range(len(targets)):\n",
    "            # tirage Bernoulli selon params[0][0]: les cibles sont elles contaminées\n",
    "            # La noeud infectieux infecte la cible j avec une probabilité p stockée dans params (parsée dans graph)\n",
    "            # On fait un test de Bernouilli (ie: binomiale avec un seul tirage)\n",
    "            p = params[0][0][j]\n",
    "            if np.random.binomial(1, p, 1):\n",
    "                # Si la cible est infectée on fait un tirage exponentiel pour connaître son temps de contamination\n",
    "                # (Tref + tirage) selon son lambda dans params[1][0]\n",
    "                lam = params[1][0][j]\n",
    "                ti = Tref + exp(lam)\n",
    "                if ti < times[targets[j]]:\n",
    "                    times[targets[j]] = ti\n",
    "                    infectious[targets[j]] = 0\n",
    "    return times\n",
    "\n",
    "np.random.seed(1)\n",
    "print(simulation(graph,[0], maxT))\n",
    "print(simulation(graph,[0], maxT))\n",
    "print(simulation(graph,[0], maxT))\n",
    "np.random.seed(1)\n",
    "print(simulation(graph,[0,1], maxT))\n",
    "print(simulation(graph,[0,1], maxT))\n",
    "print(simulation(graph,[0,1], maxT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxs-LQ3NgqHC"
   },
   "source": [
    "Vérification : \n",
    "\n",
    "```\n",
    "[ 0.          2.71669685 10.         10.         10.         10.\n",
    " 10.         10.          3.19055869  3.17528764  2.86665883]\n",
    "[ 0.          0.60940319 10.         10.         10.         10.\n",
    " 10.         10.          2.36988928 10.         10.        ]\n",
    "[ 0.          0.22787406 10.         10.         10.         10.\n",
    " 10.         10.          1.27950225  3.42920125 10.        ]\n",
    "[ 0.          0.          0.03983788  0.09306264  0.05063365  1.10889995\n",
    " 10.          1.16647819 10.          1.16739272  0.03159079]\n",
    "[ 0.          0.         10.         10.         10.         10.\n",
    "  0.16359844 10.          1.71855838 10.         10.        ]\n",
    "[ 0.          0.          3.08047501  1.49963044  3.25699405 10.\n",
    " 10.         10.          0.83189232  2.23597755 10.        ]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPpzbeS_UMXk"
   },
   "source": [
    "La méthode $getProbaMC(graph,sources,nbsimu)$ retourne les estimations de probabilités marginales d'infection des différents noeuds de $graph$, conditionnées à l'observation des  $sources$. Pour être enregistrée, une infection doit intervenir avant la seconde $maxT$. Ainsi, si la méthode retourne 0.2 pour le noeud $i$, cela indique qu'il a été infecté avec un temps $t_i \\in ]0,maxT[$ dans 20% des $nbsimu$ simulations effectuées. Compléter la méthode ci dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dV9zdHYPG7Op"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.      0.77642 0.25572 0.44175 0.22981 0.11008 0.15189 0.08933 0.58858\n",
      " 0.36184 0.38566]\n",
      "[0.      0.77608 0.25869 0.44728 0.2316  0.1128  0.15182 0.09141 0.58873\n",
      " 0.36193 0.38589]\n",
      "[0.      0.      0.35815 0.58964 0.32316 0.17678 0.20182 0.141   0.80083\n",
      " 0.50104 0.49992]\n",
      "[0.72278 0.80247 0.      0.93594 0.89964 0.49761 0.1597  0.35829 0.\n",
      " 0.44057 0.39873]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def getProbaMC(graph,sources, maxT, nbsimu=100000):\n",
    "    names,gk,gr=graph # eclatement du graphe\n",
    "    nbNodes=len(names)\n",
    "    rInf= np.zeros(nbNodes) # nb d'infection de chaque noeud dans la simulation suivante\n",
    "    # boucle for sur nbsimu\n",
    "    for k in range(nbsimu):\n",
    "        #Réalisation d'une simulation\n",
    "        sim = simulation(graph,sources,maxT)\n",
    "        #Incrément pour les noeuds contaminés dans la simulation\n",
    "        rInf += np.where((sim>0) & (sim<maxT),1,0)    #d'après la formule de l'énoncé\n",
    "    #retour de rInf (normalisé en fréquence et pas en comptage)\n",
    "    return rInf / nbsimu\n",
    "    \n",
    "\n",
    "#On obtient des 0 à la place des 1 car l'énoncé nous dit de ne pas prendre en compte les infections au temps 0 (donc ceux des sources)\n",
    "#Alors que dans la vérification il semblerait que l'on prenne en compte les temps des sources\n",
    "rInf=getProbaMC(graph,[0], maxT)\n",
    "print(rInf) \n",
    "\n",
    "rInf=getProbaMC(graph,[0], maxT)\n",
    "print(rInf)\n",
    "\n",
    "rInf=getProbaMC(graph,[0,1], maxT)\n",
    "print(rInf)  \n",
    "\n",
    "rInf=getProbaMC(graph,[2,8], maxT)\n",
    "print(rInf) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VB69myqgYia"
   },
   "source": [
    "Vérification : \n",
    "\n",
    "\n",
    "```\n",
    "[1.      0.7785  0.25939 0.44694 0.23214 0.11123 0.15518 0.09145 0.58973\n",
    " 0.36455 0.38976]\n",
    "[1.      0.77994 0.25928 0.44709 0.23307 0.11118 0.155   0.09067 0.59052\n",
    " 0.36201 0.38788]\n",
    "[1.      1.      0.35724 0.58993 0.32084 0.17582 0.20088 0.13995 0.79891\n",
    " 0.49967 0.49876]\n",
    "[0.71818 0.79804 1.      0.93559 0.89997 0.49813 0.15957 0.35803 1.\n",
    " 0.44108 0.39904]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-sluTACtRCM"
   },
   "source": [
    "Cette méthode permet de bonnes estimations (malgré une certaine variance) lorsque l'on n'a pas d'observations autres que le vecteur de sources (i.e., on estime des probabilités de la forme: $P(t_i < maxT|\\{(j,t_j),t_j=0\\})$). Par contre, si l'on souhaite obtenir des probabilités d'infection du type $P(t_i < maxT|\\{(j,t_j),t_j=0\\}, \\{(j,t_j), j \\in {\\cal O}\\})$, c'est à dire conditionnées à des observations supplémentaires pour un sous-ensembles de noeuds ${\\cal O}$ (avec $t_j > 0$ pour tout noeud $j$ de ${\\cal O}$), l'utilisation de la méthode de MonteCarlo précédente est impossible. Cela impliquerait de filtrer les simulations obtenues selon qu'elles remplissent les conditions sur les noeuds de ${\\cal O}$, ce qui nous amènerait à toutes les écarter sachant que l'on travaille avec des temps continus. \n",
    "\n",
    "Pour estimer ce genre de probabilité conditionnelle, nous allons nous appuyer sur des méthodes de type MCMC, notamment la méthode de Gibbs Sampling. Cette méthode est utile pour simuler selon une loi jointe, lorsqu'il est plus simple d'échantillonner de chaque variable conditionnellement à toutes les autres plutôt que directement de cette loi jointe. L'algorithme est donné par: \n",
    "\n",
    "\n",
    "1.   Tirage d'un vecteur de valeurs initiales pour toutes les variables $X_i$\n",
    "2.   Pour toutes les variable $X_i$ choisies dans un ordre aléatoire, échantillonnage d'une nouvelle valeur: $X_i \\sim p(x_i\\mid x_1,\\dots,x_{i-1},x_{i+1},\\dots,x_n)$\n",
    "3.   Recommencer en 2 tant qu'on souhaite encore des échantillons\n",
    "\n",
    "Notons qu'il est souvent utile d'exploiter la relation suivante, qui indique que pour échantillonner de la loi conditionnelle, il suffit d'échantillonner chaque variable proportionnellement à la loi jointe, avec toutes les autres variables fixées: \n",
    "$$p(x_j\\mid x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_n) = \\frac{p(x_1,\\dots,x_n)}{p(x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_n)} \\propto p(x_1,\\dots,x_n)$$\n",
    "\n",
    "Après une période dite de $burnin$ d'un nombre d'époques à définir, l'algorithme émet des échantillons qui suivent la loi jointe connaissant les observations. Lorsque l'objectif est d'estimer des probabilités marginales, on fait alors tourner cet algorithme pendant une certain nombre d'époques après la période de $burnin$, au cours desquelles on recence les différentes affectations de chacune des variables étudiées. \n",
    "\n",
    "Pour mettre en oeuvre cet algorithme, nous aurons aurons besoin d'avoir accès rapidement aux prédecesseurs et successeurs dans le graphe. La méthode ci-dessous retourne un couple de dictionnaires à partir du graphe: \n",
    " \n",
    "\n",
    "*   $preds[i]$  contient la liste des prédécesseurs du  noeud $i$, sous la forme d'une liste de triplets $(j,k_{j,i},r_{j,i})$ pour tous les $j$ précédant $i$ dans le graphe.    \n",
    "*   $succs[i]$  contient la liste des successeurs du  noeud $i$, sous la forme d'une liste de triplets $(j,k_{i,j},r_{i,j})$ pour tous les $j$ pointés par $i$ dans le graphe.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sPmzchnSP3r",
    "outputId": "66b3d635-6c9b-4bea-a6d7-4c9e2b60ff75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds= {1: [(0, 0.9, 0.2), (8, 0.8, 14)], 0: [(1, 0.9, 3)], 2: [(1, 0.2, 1), (3, 0.4, 0.5)], 3: [(2, 0.5, 0.2), (4, 0.9, 2), (1, 0.5, 2)], 4: [(2, 0.9, 10)], 5: [(2, 0.5, 0.5)], 7: [(5, 0.7, 15), (6, 0.1, 4)], 6: [(1, 0.2, 3)], 8: [(1, 0.8, 0.8)], 9: [(8, 0.2, 0.1), (10, 0.9, 1)], 10: [(1, 0.5, 12)]}\n",
      "succs= {0: [(1, 0.9, 0.2)], 1: [(0, 0.9, 3), (2, 0.2, 1), (3, 0.5, 2), (6, 0.2, 3), (8, 0.8, 0.8), (10, 0.5, 12)], 2: [(3, 0.5, 0.2), (4, 0.9, 10), (5, 0.5, 0.5)], 3: [(2, 0.4, 0.5)], 4: [(3, 0.9, 2)], 5: [(7, 0.7, 15)], 6: [(7, 0.1, 4)], 8: [(9, 0.2, 0.1), (1, 0.8, 14)], 10: [(9, 0.9, 1)]}\n"
     ]
    }
   ],
   "source": [
    "# pré-calcul des précécesseurs et successeurs pour gagner du temps ensuite\n",
    "def getPredsSuccs(graph):\n",
    "    names,gk,gr=graph\n",
    "    nbNodes=len(names)\n",
    "    preds={}\n",
    "    succs={}\n",
    "    for (a,b),v in gk.items():\n",
    "        s=succs.get(a,[])\n",
    "        s.append((b,v,gr[(a,b)]))\n",
    "        succs[a]=s\n",
    "        p=preds.get(b,[])\n",
    "        p.append((a,v,gr[(a,b)]))\n",
    "        preds[b]=p\n",
    "    \n",
    "    return (preds,succs)\n",
    "\n",
    "preds,succs=getPredsSuccs(graph)\n",
    "print(\"preds=\",preds)\n",
    "print(\"succs=\",succs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk-vCmVX6HtV"
   },
   "source": [
    "Pour calculer les probabilités conditionnelles, il faut prendre en compte les quantités suivantes: \n",
    "\n",
    "\n",
    "*   Probabilité pour $j$ d'être infecté par $i$ au temps $t_j$ connaissant $t_i < t_j$:  \n",
    "$$\\alpha_{i,j}=k_{i,j}r_{i,j} exp(-r_{i,j}(t_j-t_i))$$\n",
    "*   Probabilité pour $j$ de ne pas être infecté par $i$ jusqu'au temps $t$:\n",
    "$$\\beta_{i,j}=k_{i,j} exp(-r_{i,j}(t_j-t_i)) + 1 - k_{i,j}$$\n",
    "*   Probabilité pour $j$ d'être infecté au temps $t_j$ connaissant les prédecesseurs infectés avant $t_j$:\n",
    "$$h_{j}=\\prod_{i \\in preds[j], t_i<t_j} \\beta_{i,j} \\sum_{i \\in preds[i], t_i<t_j} \\alpha_{i,j} / \\beta_{i,j}$$\n",
    "*   Probabilité pour $j$ de ne pas être infecté avant $maxT$ connsaissant ses prédecesseurs infectés:\n",
    "$$g_{j}=\\prod_{i \\in preds[j], t_i<t_j} \\left(k_{i,j} exp(-r_{i,j}(maxT-t_i)) + 1 - k_{i,j}\\right)=\\prod_{i \\in preds[j], t_i<t_j} \\beta_{i,j}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dans la méthode $computeab(v, times, preds)$, on prépare le calcul et les mises à jour de ces quantités. La méthode calcule, pour un noeud $v$ selon les temps d'infection courants donnés dans $times$, deux quantités $a$ et $b$: \n",
    "\n",
    "$$a= \\left\\{\n",
    "\\begin{array}{l}\n",
    "\\max(1e^{-20}, \\sum_{i \\in preds[v], t_i<t_v} \\alpha_{i,v} / \\beta_{i,v}) \\mbox{ si: } t_v< maxT \\\\\n",
    "1 \\mbox{ sinon }\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$ \n",
    "\n",
    "$$b=\\sum_{i \\in preds[v], t_i<t_v} \\log \\beta_{i,v}$$\n",
    "\n",
    "Si $v$ appartient aux sources, on retourne $(a,b)=(1,0)$\n",
    "\n",
    "Compléter la méthode $computeab$ donnée ci-dessous:   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cOnGCJCBSulp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0)\n",
      "(0.17610107365772137, -0.17810126145719926)\n",
      "(0.012293749653343879, -0.21077360840944234)\n",
      "(1, -1.1230118785518794)\n"
     ]
    }
   ],
   "source": [
    "eps=1e-20\n",
    "from math import exp,log\n",
    "\n",
    "def computeab(v, times, preds, maxT, eps=1e-20):\n",
    "    preds = preds.get(v,[])\n",
    "    t = times[v]\n",
    "    if t==0:\n",
    "        return (1,0)\n",
    "\n",
    "    if len(preds)>0:\n",
    "        # Tous les prédécesseurs dans c\n",
    "        # Tous les ki des prédécesseurs dans k\n",
    "        # Tous les ri des prédécesseurs dans r\n",
    "        c, k, r= map(np.array,zip(*preds)) # mise en forme des prédécesseurs\n",
    "        \n",
    "        # Initialisation des deux sommes et sommation en même temps pour éviter\n",
    "        # de faire deux boucles identiques\n",
    "        somme_a = 0\n",
    "        somme_b = 0\n",
    "        for i in range(len(preds)):\n",
    "            if times[c[i]] < t:\n",
    "                # Calcul des sommes dans la même boucle\n",
    "                delta_t = t - times[c[i]]\n",
    "                alpha = k[i] * r[i] * exp(-r[i]*delta_t)\n",
    "                beta = k[i] * exp(-r[i]*delta_t) + 1 - k[i]\n",
    "                somme_a += alpha/beta\n",
    "                somme_b += log(beta)\n",
    "        # Si t=maxT alors on n'utilise pas la somme_A\n",
    "        if t == maxT:\n",
    "            return (1, somme_b)\n",
    "        else: # Sinon on renvoit le max entre somme_A et epsilon\n",
    "            return max(eps,somme_a), somme_b\n",
    "\n",
    "nbNodes=len(graph[0])\n",
    "times=np.array([maxT]*nbNodes,dtype=float)\n",
    "times[0]=0\n",
    "times[1]=1\n",
    "times[2]=4\n",
    "\n",
    "print(computeab(0,times,preds, maxT, eps))\n",
    "print(computeab(1,times,preds, maxT, eps))\n",
    "print(computeab(2,times,preds, maxT, eps))\n",
    "print(computeab(3,times,preds, maxT, eps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujNcsUdcfKYR"
   },
   "source": [
    "Vérification : \n",
    "\n",
    "\n",
    "```\n",
    "(1, 0)\n",
    "(0.17610107365772135, -0.17810126145719926)\n",
    "(0.012293749653343877, -0.2107736084094422)\n",
    "(1.0, -1.12301187855188)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXnKXCMfLMK-"
   },
   "source": [
    "La méthode $computell$ calcule la log-vraisemblance d'une diffusion (représentée par le tableau times), en appelant la méthode computeab sur l'ensemble des noeuds du réseau. Elle retourne un triplet (log-likelihood, sa, sb), avec $sa$ et $sb$ les tables des valeurs $a$ et $b$ pour tous les noeuds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aM0K-VhPUXJn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll= -13.117139892397578\n",
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "like_indiv= [1.         0.14737154 0.00995741 0.32529856 0.1        0.52489353\n",
      " 0.8        1.         0.20059727 1.         0.5       ]\n"
     ]
    }
   ],
   "source": [
    "def computell(times,preds, maxT, eps):\n",
    "    n = len(times)\n",
    "    sa, sb = np.zeros((n)), np.zeros((n))\n",
    "    ll = 0.0\n",
    "    for v in range(n):\n",
    "        #calcul de a,b pour tous les v\n",
    "        a,b = computeab(v, times, preds, maxT)\n",
    "        sa[v], sb[v] = a,b\n",
    "    #calcul de la log-vraisemblance\n",
    "        ll += log(a) + b\n",
    "    return ll, sa, sb\n",
    "\n",
    "ll,sa,sb=computell(times,preds, maxT, eps)\n",
    "print(\"ll=\",ll)\n",
    "print(times)\n",
    "print(\"like_indiv=\",np.exp(np.log(sa)+sb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akb4kVy3hK2X"
   },
   "source": [
    "Vérification : \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "ll= -13.117139892397578\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "like_indiv= [1.         0.14737154 0.00995741 0.32529856 0.1        0.52489353\n",
    " 0.8        1.         0.20059727 1.         0.5       ]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNlDzJeFNb60"
   },
   "source": [
    "Afin de préparer les mises à jour lors des affectations successives des variables du Gibbs Sampling, on propose de définir une méthode $removeV(v,times,succs,sa,sb)$ qui retire temporairement du réseau un noeud $v$, en passant son temps d'infection à -1 dans times et en retirant sa contribution aux valeurs a et b (contenues dans sa et sb) de tous ses successeurs $j$ tels que $t_j > t_v$ (y compris donc les non infectés qui sont à $t_j=maxT$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEGzpS_DaRX5",
    "outputId": "f1cd5174-87e0-426e-f665-f4a1b2ed89f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa= [1.         0.17610107 0.01229375 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.        ]\n",
      "sb= [ 0.         -0.17810126 -0.21077361 -1.12301188 -2.30258509 -0.64455983\n",
      " -0.22314355  0.         -1.60645602  0.         -0.69314718]\n",
      "diffa= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "diffb= [0.         0.         0.         1.12301188 0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "diffa= [ 0.          0.82389893 -0.01229375  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "diffb= [0.         0.17810126 0.21077361 0.69314717 0.         0.\n",
      " 0.22314355 0.         1.60645602 0.         0.69314718]\n"
     ]
    }
   ],
   "source": [
    "def removeV(v,times,succs,sa,sb):\n",
    "    succs=succs.get(v,[])\n",
    "    t=times[v]\n",
    "    if t<0:\n",
    "        return \n",
    "    times[v]=-1\n",
    "    sa[v]=1.0\n",
    "    sb[v]=0.0\n",
    "    if len(succs)>0:\n",
    "        c,k,r=map(np.array,zip(*succs))\n",
    "        tp=times[c]\n",
    "        which=(tp>t)\n",
    "\n",
    "        tp=tp[which]\n",
    "        dt=tp-t\n",
    "        k=k[which]\n",
    "        r=r[which]\n",
    "        c=c[which]\n",
    "        rt = -r*dt\n",
    "        b1=k*np.exp(rt)\n",
    "        b=b1+1.0-k\n",
    "\n",
    "        a=r*b1\n",
    "        a=a/b\n",
    "        b=np.log(b)\n",
    "\n",
    "        sa[c]=sa[c]-np.where(tp<maxT,a,0.0)\n",
    "        sa[c]=np.where(sa[c]>eps,sa[c],eps)\n",
    "        sb[c]=sb[c]-b\n",
    "        sb[c]=np.where(sb[c]>0,0,sb[c])\n",
    "\n",
    "\n",
    "#Test\n",
    "print(\"sa=\",sa)\n",
    "print(\"sb=\",sb)\n",
    "\n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "ntimes=np.copy(times)\n",
    "removeV(3,ntimes,succs,nsa,nsb)\n",
    "print(\"diffa=\",nsa-sa)\n",
    "print(\"diffb=\",nsb-sb)\n",
    "\n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "ntimes=np.copy(times)\n",
    "removeV(1,ntimes,succs,nsa,nsb)\n",
    "print(\"diffa=\",nsa-sa)\n",
    "print(\"diffb=\",nsb-sb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb8iIMwgO6D9"
   },
   "source": [
    "La méthode addVatT fait l'inverse: elle rajoute un noeud qui était retiré du réseau, avec un temps $newt$. Il faut alors mettre à jour les valeurs a et b (dans sa et sb) de tous les successeurs de $v$ tels que $t_j > newt$ et calculer les valeurs a et b du noeud v. \n",
    "\n",
    "Compléter le code ci-dessous: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9sDiLiXnngog"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.830251606174211e-05 8.555487921315824e-05 3.830251606174211e-05 -13.117139892397578\n",
      "0.14737153555403676 1.0000000000169125e-21 0.14737153555403676 -13.117139892397578\n",
      "0.524893534183932 2.999999999999998e-21 0.524893534183932 -13.117139892397578\n"
     ]
    }
   ],
   "source": [
    "def addVatT(v,times,newt,preds,succs,sa,sb, maxT):\n",
    "    t=times[v]\n",
    "    if t>=0:\n",
    "        raise Error(\"v  must have been removed before\")\n",
    "        \n",
    "    #mise à jour du nouveau temps dans times\n",
    "    times[v] = newt\n",
    "    \n",
    "    #mise à jour a et b dans les vecteurs sa et sb\n",
    "    sa[v], sb[v] = computeab(v, times, preds, maxT, eps=1e-20)\n",
    "    \n",
    "    #mise à jour des tous les successeurs de v\n",
    "    for j in preds:\n",
    "        sa[j], sb[j] = computeab(j,times,preds,maxT)\n",
    "    pass\n",
    "        \n",
    "# Tests: \n",
    "   \n",
    "nsa=np.copy(sa)\n",
    "nsb=np.copy(sb)\n",
    "c,_,_=map(np.array,zip(*succs[1]))\n",
    "c=np.append(c,1)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])           # somme des logvraisemblances pouvant être modifiées par la modification du temps de 1 (avant modif)\n",
    "removeV(1,times,succs,nsa,nsb)\n",
    "addVatT(1,times,2,preds,succs,nsa,nsb, maxT)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])          # somme des logvraisemblances pouvant avoir été modifiées par la modification du temps de 1 (après modif)\n",
    "removeV(1,times,succs,nsa,nsb)\n",
    "addVatT(1,times,1,preds,succs,nsa,nsb, maxT)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])          # somme des logvraisemblances pouvant  avoir été modifiées par la modification du temps de 1 (après remise dans l'état initial)\n",
    "llall=np.sum(np.log(nsa)+nsb)             # logvraisemblance globale\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n",
    "\n",
    "c,_,_=map(np.array,zip(*succs[0]))\n",
    "c=np.append(c,0)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(0,times,succs,nsa,nsb)\n",
    "addVatT(0,times,maxT,preds,succs,nsa,nsb, maxT)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(0,times,succs,nsa,nsb)\n",
    "addVatT(0,times,0,preds,succs,nsa,nsb, maxT)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])\n",
    "llall=np.sum(np.log(nsa)+nsb)\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n",
    "\n",
    "c,_,_=map(np.array,zip(*succs[5]))\n",
    "c=np.append(c,5)\n",
    "ll=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(5,times,succs,nsa,nsb)\n",
    "addVatT(5,times,1,preds,succs,nsa,nsb, maxT)\n",
    "ll2=np.sum((np.log(nsa)+nsb)[c])\n",
    "removeV(5,times,succs,nsa,nsb)\n",
    "addVatT(5,times,maxT,preds,succs,nsa,nsb, maxT)\n",
    "ll3=np.sum((np.log(nsa)+nsb)[c])\n",
    "llall=np.sum(np.log(nsa)+nsb)\n",
    "print(np.exp(ll),np.exp(ll2),np.exp(ll3),llall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBg9T8k2hhmO"
   },
   "source": [
    "Vérification : \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "3.830251606174211e-05 8.555487921315824e-05 3.830251606174211e-05 -13.117139892397578\n",
    "0.14737153555403676 1.0000000000169125e-21 0.14737153555403676 -13.117139892397578\n",
    "0.5248935341839319 2.999999999999998e-21 0.5248935341839319 -13.117139892397578\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3isBRUNi3JPA"
   },
   "source": [
    "Pour échantillonner pour une variable $i$, il faudra être à même de comparer les vraisemblances selon les différentes affectations. Cela implique de calculer la somme de toutes ces vraisemblances. Mais pour réaliser cette somme, il faudrait que nous sortions de la représentation logarithmique: $\\sum_{t_i} exp(log(p(t_1,\\dots,t_i,\\dots,t_n))$. Si on le fait de cette manière, on risque d'avoir des arrondis à 0 presque partout. Une possibilité (log-sum-exp trick) est d'exploiter la relation suivante:  \n",
    "\n",
    "$$\\log\\sum_i x_i = x^* + \\log\\left( \\exp(x_1-x^*)+ \\cdots + \\exp(x_n-x^*) \\right)$$\n",
    "avec $x^* = \\max{\\{x_1, \\dots, x_n\\}}$\n",
    "\n",
    "Compléter la méthode logsumexp suivante, qui réalise cette somme en évitant les problèmes numériques: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZuOJI7B3p0O",
    "outputId": "dd48b42f-6b96-4121-9a1c-291e8468288f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.54045945 -0.67334455] [-3.54045945 -0.67334455]\n"
     ]
    }
   ],
   "source": [
    "def logsumexp(x,axis=-1):\n",
    "    xe = np.max(x)\n",
    "    return xe + np.log(np.sum(np.exp(x - xe),axis=1)) #somme sur les lignes\n",
    "  \n",
    "\n",
    "#Test: \n",
    "x=np.array([[0.001,0.02,0.008],[0.1,0.01,0.4]])\n",
    "r=np.log(np.sum(x,-1))\n",
    "x=np.log(x)\n",
    "r2=logsumexp(x)\n",
    "print(r2,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZpzgRBZhtOm"
   },
   "source": [
    "Vérification : \n",
    "\n",
    "\n",
    "```\n",
    "[-3.54045945 -0.67334455] [-3.54045945 -0.67334455]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqVI0e9T85x-"
   },
   "source": [
    "On souhaite maintenant mettre en place une méthode $sampleV(v,times,newt,preds,succs,sa,sb,k,k2)$ qui sample un nouveau temps d'infection pour le noeud $v$, connaissant les temps de tous les autres noeuds dans $times$ (ainsi que leurs valeurs $a$ et $b$ correspondantes contenues dans sa et sb). Puisque le domaine de support de $t_v$ est continu, on doit faire quelques approximations en se basant sur une discrétisation des valeurs possibles:\n",
    "\n",
    "1.   On découpe la plage de temps $[0;maxT]$ en $k$ bins réguliers. Dans chaque bin $i$, on échantillonne uniformément un temps, pour obtenir $k$ points $d_1,\\dots,d_k$. Si $t_v < maxT$, on ajoute $t_v$ à cet ensemble de points pour gagner en stabilité (inséré dans la liste de manière à conserver l'ordre croissant). \n",
    "2.   On considère chaque point $d_i$ comme le prototype d'un bin $[(d_i+d_{i-1})/2,(d_i+d_{i+1})/2]$. Pour $d_1$ on prend $[0,(d_1+d_2)/2]$ et pour $d_k$ on prend   $[(d_k+d_{k-1})/2,maxT]$. On fait l'hypothèse que la densité de probabilité est constante sur l'ensemble de chaque bin $i$, que l'on évalue en  $t_v=d_i$.   La probabilité que l'on échantillonne dans le bin $i$ est alors égale à: $p(t_v \\in bin_i | \\{t_u\\}_{ u \\in V\\setminus v}) =  \\frac{z_i \\times l_i}{\\sum_j z_j \\times l_j + z_{maxT}}$, avec $z_i$ la vraisemblance  calculée selon $t_v =d_i$, $l_i$ la taille du bin $i$ et $z_{maxT}$ la vraisemblance  calculée pour $t_v=maxT$. La probabilité que $v$ ne soit pas infecté dans la diffusion est alors donnée par : $p(t_v = maxT | \\{t_u\\}_{ u \\in V\\setminus v}) =  \\frac{z_{maxT}}{\\sum_j z_j \\times l_j + z_{maxT}}$.\n",
    "3. On échantillonne une variable $x$ proportionnellement aux probabilités calculées à l'étape précédente.  Si $x$ ne correspond pas à $maxT$, $v$ est alors infecté à un temps inclus dans l'intervale du bin correspondant à $x$. Il s'agit alors de re-échantillonner $k2$ points uniformément dans ce bin et de calculer les densités en ces points (pour gagner en stabilité on ajoute le prototype du bin $d_i$). Le nouveau temps de $v$ est alors échantillonné proportionnellement à ces densités.\n",
    "\n",
    "Le code de la méthode de sampling est donné ci-dessous:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "K3QmBCRbhkLM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'll' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-162b3f3bb2c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0msampleV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuccs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0msampleV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuccs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-162b3f3bb2c0>\u001b[0m in \u001b[0;36msampleV\u001b[0;34m(v, times, preds, succs, sa, sb, k, k2, maxT)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mnsb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mremoveV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuccs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mlls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuccs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0monUsers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mla\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-162b3f3bb2c0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mnsb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mremoveV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuccs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mlls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuccs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0monUsers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mla\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-162b3f3bb2c0>\u001b[0m in \u001b[0;36mgetLL\u001b[0;34m(v, times, nt, preds, succs, sa, sb, maxT, onUsers)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0monUsers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'll' referenced before assignment"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "\n",
    "def getLL(v,times,nt,preds,succs,sa,sb, maxT, onUsers=None):\n",
    "    sa=np.copy(sa)\n",
    "    sb=np.copy(sb)\n",
    "    if onUsers is None:\n",
    "        onUsers=range(len(times))\n",
    "        addVatT(v,times,nt,preds,succs,sa,sb, maxT)\n",
    "        times[v]=-1\n",
    "        ll=np.sum((np.log(sa)+sb)[onUsers])\n",
    "    return (ll,sa,sb)\n",
    "\n",
    "  \n",
    "def sampleV(v,times,preds,succs,sa,sb,k,k2, maxT):\n",
    "  \n",
    "    nbCandidateT=k\n",
    "    bounds=np.linspace(0,maxT,nbCandidateT)\n",
    "    newt=np.random.uniform(bounds[:-1],bounds[1:])\n",
    "  \n",
    "    if times[v]<maxT:\n",
    "        idx = newt.searchsorted(times[v])\n",
    "        newt=np.concatenate((newt[:idx], [times[v]], newt[idx:]),axis=0)\n",
    "        nbCandidateT+=1\n",
    "    newt=np.append(newt,[maxT])\n",
    "  \n",
    "    if v in succs:\n",
    "        c,_,_=map(list,zip(*succs.get(v,[])))\n",
    "    else:\n",
    "        c=[]\n",
    "    c.append(v)\n",
    "    c=np.array(c)\n",
    "    oldll=np.sum((np.log(sa)+sb)[c])\n",
    "    otime=times[v]\n",
    "    nsa=np.copy(sa)\n",
    "    nsb=np.copy(sb)\n",
    "    removeV(v,times,succs,nsa,nsb)\n",
    "    lls=[getLL(v,times,nt,preds,succs,nsa,nsb, maxT,onUsers=c) for nt in newt]\n",
    "    ll,la,lb=zip(*lls)\n",
    "    ll=list(ll)\n",
    "    ll=np.array(ll)\n",
    "\n",
    "    diffsx=(newt[1:]-newt[:-1])/2.0\n",
    "    diffsx[1:]=diffsx[1:]+diffsx[:-1]\n",
    "    diffsx[0]+=newt[0]\n",
    "    diffsx[-1]+=(maxT-newt[nbCandidateT-1])/2.0\n",
    "    areas=np.log(diffsx)+ll[:-1]\n",
    "    lln=np.append(areas,ll[-1])\n",
    "  \n",
    "\n",
    "    p=np.exp(lln-logsumexp(lln))\n",
    "\n",
    "\n",
    "    i=np.random.choice(range(len(p)),1,p=p).sum()\n",
    "    if i==(len(p)-1):\n",
    "        times[v]=maxT\n",
    "        np.copyto(sa,np.array(la[-1]))\n",
    "        np.copyto(sb,np.array(lb[-1]))\n",
    "    else: \n",
    "        if i>0: \n",
    "            bi=(newt[i]+newt[i-1])/2.0\n",
    "        else:\n",
    "            bi=0\n",
    "        if i<(len(p)-2): \n",
    "            bs=(newt[i]+newt[i+1])/2.0\n",
    "        else:\n",
    "            bs=maxT\n",
    "            bounds=np.linspace(bi,bs,k2)\n",
    "            newt=np.concatenate(([newt[i]],np.random.uniform(bounds[:-1],bounds[1:])))\n",
    "            lls=[getLL(v,times,nt,preds,succs,nsa,nsb, maxT, onUsers=c) for nt in newt]\n",
    "            ll,la,lb=zip(*lls)\n",
    "            ll=np.array(ll)\n",
    "            p=np.exp(ll-logsumexp(ll))\n",
    "\n",
    "        i=np.random.choice(range(len(p)),1,p=p).sum()\n",
    "\n",
    "        times[v]=newt[i]\n",
    "        np.copyto(sa,np.array(la[i]))\n",
    "        np.copyto(sb,np.array(lb[i]))\n",
    "\n",
    "times=np.array([maxT]*nbNodes,dtype=float)\n",
    "times[0]=0\n",
    "times[1]=1\n",
    "times[2]=4\n",
    "np.random.seed(0)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10, maxT)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10, maxT)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10, maxT)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10, maxT)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10, maxT)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10, maxT)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10, maxT)\n",
    "print(times)\n",
    "sampleV(5,times,preds,succs,sa,sb,10,10, maxT)\n",
    "print(times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RMM_c2siHez"
   },
   "source": [
    "Vérification : \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "[ 0.          1.          4.         10.         10.          4.20931617\n",
    " 10.         10.         10.         10.         10.        ]\n",
    "[ 0.  1.  4. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCdSA3NF8CrE"
   },
   "source": [
    "Compléter la méthode de Gibbs Sampling $gb$ ci-dessous, avec $k$ le nombre de bins à utiliser et $k2$ le nombre de points à échantillonner dans le bin choisi. Le paramètre $ref$ correspond à un vecteur de probabilités marginales de référence (par exemple obtenu par MonteCarlo lorsque c'est possible) avec lequel on peut afficher la distance MSE au fur et à mesure du processus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsnQHVcdjfVT",
    "outputId": "8c274aa7-e425-4ed7-d3a6-a114a85988b8"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-acbda08cb5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# On teste ici avec seulement des sources (i.e., des infectés au temps 0), car cela permet de comparer à la ref MonteCarlo (mais il faudrait aussi tester avec d'autres infectés : c'est l'objectif).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetProbaMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mburnin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-170f0fc980a5>\u001b[0m in \u001b[0;36mgetProbaMC\u001b[0;34m(graph, sources, maxT, nbsimu)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbsimu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#Réalisation d'une simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m#Incrément pour les noeuds contaminés dans la simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrInf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mmaxT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#d'après la formule de l'énoncé\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4298687f6de9>\u001b[0m in \u001b[0;36msimulation\u001b[0;34m(graph, sources, maxT)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# On boucle tant qu'il reste des contaminants (ie: qu'il reste des 0 dans infectious)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfectious\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# trouver le noeud contaminant à cette itération = argmin dans infectious\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mNoeud_contaminant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfectious\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "def gb(graph,infections, maxT, times, burnin=1000,nbEpochs=10000,k=100,k2=50, ref=None):\n",
    "    eps = 1e-5\n",
    "    rate = []\n",
    "    preds, succs = getPredsSuccs(graph)\n",
    "    sample = times.copy()\n",
    "    #On génère tous les noeuds du système\n",
    "    nbNodes = len(graph[0])\n",
    "    #nombre d'échantillons à réaliser\n",
    "    for i in range(nbEpochs):\n",
    "        nodes = np.arange(nbNodes)\n",
    "        #Pour chaque noeud on va générer un échantillon\n",
    "        for j in range(nbNodes):\n",
    "            ll, sa, sb = computell(times, preds, maxT,eps)\n",
    "            v = np.random.choice(nodes)\n",
    "            #On enlève ensuite chaque dans nodes pour ne pas retomber sur le même\n",
    "            np.delete(nodes,v)\n",
    "            #On échantillone selon les paramètres\n",
    "            sampleV(v,times,preds,succs,sa,sb,k,k2)\n",
    "            #Ensuite quand on a réalisé tous les échantillons on calcule la distance  mse = (x1 - x2)²\n",
    "            if i > burnin:\n",
    "                rate.append((times - ref)**2)\n",
    "    return rate\n",
    "\n",
    "# On teste ici avec seulement des sources (i.e., des infectés au temps 0), car cela permet de comparer à la ref MonteCarlo (mais il faudrait aussi tester avec d'autres infectés : c'est l'objectif). \n",
    "ref=getProbaMC(graph,[0], maxT) \n",
    "rate=gb(graph,[(0,0)],maxT, times, burnin=100,ref=ref)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqx6CQ4vQ8rr"
   },
   "source": [
    "# Partie optionnelle\n",
    "\n",
    "L'algorithme de Metropolis-Hasting est une autre méthode de type MCMC qui utilise une distribution d'échantillonnage pour se déplacer dans l'espace des points considérés. Il s'agit de définir une distribution $q(y_{t+1}|x_t)$ de laquelle on sait générer un déplacement. L'algorithme procéde alors de la manière suivante: \n",
    "\n",
    "\n",
    "1.   Générer $y_{t+1}$ selon $q(y_{t+1}|x_t)$ \n",
    "2.   Calculer la probabilité d’acceptation $\\alpha(x_t,y_{t+1})=\\min\\left\\{\\frac{\\pi(y_{t+1})q(x_t|y_{t+1})}{\\pi(x_t)q(y_{t+1}|x_t)},1\\right\\} \\,\\!, \\text{ avec } \\pi(x_t) \\text{ la densité de probabilité de } x_t$\n",
    "3.   Prendre $x_{t+1}=\\begin{cases} y_{t+1}, & \\text{avec probabilité}\\,\\,\\alpha \\\\ x_t, & \\text{avec probabilité}\\,\\,1-\\alpha \\end{cases}$\n",
    "\n",
    "\n",
    "\n",
    "Dans notre cas, on propose de travailler avec des déplacements correspondants à des permutations d'un temps d'infection à chaque itération, comme dans le cadre du Gibbs Sampling. A chaque étape on choisit donc une variable à modifier, on choisit un nouveau temps pour cette variable et on calcule la densité correspondante. La probabilité d'acceptation est ensuite calculée selon cette densité et la probabilité du déplacement selon la distribution $q$ qui a servi à générer le nouveau temps d'infection. On se propose de choisir $maxT$ avec une probabilité de 0.1. La probabilité $q(t_v|t)$ pour $t< maxT$ est alors égale  à  $0.9\\times \\frac{1}{maxT}$.\n",
    "\n",
    "Implémenter l'approche d'échantillonnage par Metropolis-Hasting pour notre problème d'estimation de probabilités marginales d'infection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGoHITZmGxg-",
    "outputId": "e463281e-3ce0-4bba-c8b3-c2b44fbf8f7c"
   },
   "outputs": [],
   "source": [
    "# votre code ici\n",
    "\n",
    "ref=getProbaMC(graph,[0]) \n",
    "rate=mh(graph,[(0,0)],burnin=100,ref=ref)\n",
    "print(rate)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tme8_mapsi_2020_enonce",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
